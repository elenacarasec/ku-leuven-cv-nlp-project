{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MkoGLH_Tj5wn"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "ORj09gnrj5wp"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I6hghKPxj5w0"
   },
   "source": [
    "## Model Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 23936,
     "status": "ok",
     "timestamp": 1524974497505,
     "user": {
      "displayName": "Sebastian Raschka",
      "photoUrl": "//lh6.googleusercontent.com/-cxK6yOSQ6uE/AAAAAAAAAAI/AAAAAAAAIfw/P9ar_CHsKOQ/s50-c-k-no/photo.jpg",
      "userId": "118404394130788869227"
     },
     "user_tz": 240
    },
    "id": "NnT0sZIwj5wu",
    "outputId": "55aed925-d17e-4c6a-8c71-0d9b3bde5637"
   },
   "outputs": [],
   "source": [
    "RANDOM_SEED = 1\n",
    "LEARNING_RATE = 0.0001\n",
    "BATCH_SIZE = 32\n",
    "NUM_EPOCHS = 20\n",
    "\n",
    "RESOLUTION = 200\n",
    "\n",
    "NUM_FEATURES = RESOLUTION*RESOLUTION\n",
    "NUM_CLASSES = 66\n",
    "\n",
    "DEVICE = \"cuda:0\"\n",
    "GRAYSCALE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize(RESOLUTION),\n",
    "    transforms.CenterCrop(RESOLUTION),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "path = 'CV_data/Extracted_dataset_input_combined'\n",
    "dataset = datasets.ImageFolder(root=path, transform=transform)\n",
    "\n",
    "\n",
    "# Get class to index mapping\n",
    "class_to_idx = dataset.class_to_idx\n",
    "\n",
    "# Define index to class mapping\n",
    "idx_to_class = {v: k for k, v in class_to_idx.items()}\n",
    "\n",
    "train_size = int(0.6 * len(dataset))\n",
    "val_size = int(0.2 * len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size\n",
    "\n",
    "# Split the dataset into training set and test set\n",
    "train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(\n",
    "    dataset, [train_size, val_size, test_size])\n",
    "\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, \n",
    "                          batch_size=BATCH_SIZE, \n",
    "                          shuffle=True)\n",
    "\n",
    "val_loader = DataLoader(dataset=val_dataset, \n",
    "                        batch_size=BATCH_SIZE, \n",
    "                        shuffle=False)\n",
    "\n",
    "test_loader = DataLoader(dataset=test_dataset, \n",
    "                         batch_size=BATCH_SIZE, \n",
    "                         shuffle=True)\n",
    "\n",
    "# Checking the dataset\n",
    "for images, labels in train_loader:  \n",
    "    print('Image batch dimensions:', images.shape)\n",
    "    print('Image label dimensions:', labels.shape)\n",
    "    print('Labels:', labels)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(DEVICE)\n",
    "torch.manual_seed(0)\n",
    "\n",
    "for epoch in range(2):\n",
    "\n",
    "    for batch_idx, (x, y) in enumerate(train_loader):\n",
    "        \n",
    "        print('Epoch:', epoch+1, end='')\n",
    "        print(' | Batch index:', batch_idx, end='')\n",
    "        print(' | Batch size:', y.size()[0])\n",
    "        \n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n",
    "                               padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * 4)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, num_classes, grayscale):\n",
    "        self.inplanes = 64\n",
    "        if grayscale:\n",
    "            in_dim = 1\n",
    "        else:\n",
    "            in_dim = 3\n",
    "        super(ResNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_dim, 64, kernel_size=7, stride=2, padding=3,\n",
    "                               bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
    "        self.avgpool = nn.AvgPool2d(7, stride=1)\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, (2. / n)**.5)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        \n",
    "        x = x.view(x.size(0), -1)\n",
    "        logits = self.fc(x)\n",
    "        probas = F.softmax(logits, dim=1)\n",
    "        return logits, probas\n",
    "\n",
    "\n",
    "\n",
    "def resnet50(num_classes):\n",
    "    \"\"\"Constructs a ResNet-50 model.\"\"\"\n",
    "    model = ResNet(block=Bottleneck, \n",
    "                   layers=[3, 4, 6, 3],\n",
    "                   num_classes=NUM_CLASSES,\n",
    "                   grayscale=GRAYSCALE)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "_lza9t_uj5w1"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "model = resnet50(NUM_CLASSES)\n",
    "model.to(DEVICE)\n",
    " \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(model, data_loader, device, mode=\"train\"):\n",
    "    correct_pred, num_examples = 0, 0\n",
    "    for batch_idx, (features, targets) in tqdm(enumerate(data_loader)):\n",
    "            \n",
    "        features = features.to(DEVICE)\n",
    "        targets = targets.to(DEVICE)\n",
    "\n",
    "        logits, probas = model(features)\n",
    "        _, predicted_labels = torch.max(probas, 1)\n",
    "        num_examples += targets.size(0)\n",
    "        correct_pred += (predicted_labels == targets).sum()\n",
    "        \n",
    "        if not batch_idx % 50:\n",
    "            accuracy = correct_pred.float() / num_examples * 100\n",
    "            with open(f'CV_data/models/{model_name}-{LEARNING_RATE}-{mode}-accuracy.csv', 'a') as fp:\n",
    "                fp.write(f\"{epoch+1}, {batch_idx}, {accuracy}\\n\")\n",
    "            correct_pred, num_examples = 0, 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(model, data_loader, class_weights, device, mode=\"val\"):\n",
    "    losses = []\n",
    "    dataset_len = len(data_loader)\n",
    "    for batch_idx, (features, targets) in tqdm(enumerate(data_loader)):\n",
    "        \n",
    "        features = features.to(DEVICE)\n",
    "        targets = targets.to(DEVICE)\n",
    "        class_weights = class_weights.to(DEVICE)\n",
    "            \n",
    "        logits, _ = model(features)\n",
    "        loss = F.cross_entropy(logits, targets)\n",
    "        losses.append(loss)\n",
    "        \n",
    "        if not batch_idx % 50:\n",
    "            mean_loss = sum(losses) / len(losses)\n",
    "            with open(f'CV_data/models/{model_name}-{LEARNING_RATE}-{mode}-loss.csv', 'a') as fp:\n",
    "                fp.write(f\"{epoch+1}, {batch_idx}, {mean_loss}\\n\")\n",
    "            losses.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_name = \"00-model\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RAodboScj5w6"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 1547
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2384585,
     "status": "ok",
     "timestamp": 1524976888520,
     "user": {
      "displayName": "Sebastian Raschka",
      "photoUrl": "//lh6.googleusercontent.com/-cxK6yOSQ6uE/AAAAAAAAAAI/AAAAAAAAIfw/P9ar_CHsKOQ/s50-c-k-no/photo.jpg",
      "userId": "118404394130788869227"
     },
     "user_tz": 240
    },
    "id": "Dzh3ROmRj5w7",
    "outputId": "5f8fd8c9-b076-403a-b0b7-fd2d498b48d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001/020 | Batch 0000/1284 | Cost: 4.2649\n",
      "Epoch: 001/020 | Batch 0050/1284 | Cost: 3.8272\n",
      "Epoch: 001/020 | Batch 0100/1284 | Cost: 3.5944\n",
      "Epoch: 001/020 | Batch 0150/1284 | Cost: 3.7192\n",
      "Epoch: 001/020 | Batch 0200/1284 | Cost: 3.3314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/leuven/354/vsc35486/miniconda3/lib/python3.10/site-packages/PIL/Image.py:992: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001/020 | Batch 0250/1284 | Cost: 3.0997\n",
      "Epoch: 001/020 | Batch 0300/1284 | Cost: 3.1404\n",
      "Epoch: 001/020 | Batch 0350/1284 | Cost: 2.5295\n",
      "Epoch: 001/020 | Batch 0400/1284 | Cost: 2.7810\n",
      "Epoch: 001/020 | Batch 0450/1284 | Cost: 2.8899\n",
      "Epoch: 001/020 | Batch 0500/1284 | Cost: 2.6300\n",
      "Epoch: 001/020 | Batch 0550/1284 | Cost: 2.3803\n",
      "Epoch: 001/020 | Batch 0600/1284 | Cost: 2.2133\n",
      "Epoch: 001/020 | Batch 0650/1284 | Cost: 2.6430\n",
      "Epoch: 001/020 | Batch 0700/1284 | Cost: 1.9110\n",
      "Epoch: 001/020 | Batch 0750/1284 | Cost: 1.8039\n",
      "Epoch: 001/020 | Batch 0800/1284 | Cost: 2.4884\n",
      "Epoch: 001/020 | Batch 0850/1284 | Cost: 1.8090\n",
      "Epoch: 001/020 | Batch 0900/1284 | Cost: 1.6273\n",
      "Epoch: 001/020 | Batch 0950/1284 | Cost: 1.8678\n",
      "Epoch: 001/020 | Batch 1000/1284 | Cost: 1.6614\n",
      "Epoch: 001/020 | Batch 1050/1284 | Cost: 1.4066\n",
      "Epoch: 001/020 | Batch 1100/1284 | Cost: 1.3027\n",
      "Epoch: 001/020 | Batch 1150/1284 | Cost: 1.4242\n",
      "Epoch: 001/020 | Batch 1200/1284 | Cost: 1.4810\n",
      "Epoch: 001/020 | Batch 1250/1284 | Cost: 1.0679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1284it [02:12,  9.72it/s]\n",
      "428it [00:55,  7.74it/s]\n",
      "428it [00:40, 10.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 8.59 min\n",
      "Epoch: 002/020 | Batch 0000/1284 | Cost: 1.7066\n",
      "Epoch: 002/020 | Batch 0050/1284 | Cost: 1.1887\n",
      "Epoch: 002/020 | Batch 0100/1284 | Cost: 1.5444\n",
      "Epoch: 002/020 | Batch 0150/1284 | Cost: 1.0590\n",
      "Epoch: 002/020 | Batch 0200/1284 | Cost: 1.4377\n",
      "Epoch: 002/020 | Batch 0250/1284 | Cost: 1.1466\n",
      "Epoch: 002/020 | Batch 0300/1284 | Cost: 0.7916\n",
      "Epoch: 002/020 | Batch 0350/1284 | Cost: 1.1159\n",
      "Epoch: 002/020 | Batch 0400/1284 | Cost: 1.1256\n",
      "Epoch: 002/020 | Batch 0450/1284 | Cost: 0.9754\n",
      "Epoch: 002/020 | Batch 0500/1284 | Cost: 1.2763\n",
      "Epoch: 002/020 | Batch 0550/1284 | Cost: 0.6040\n",
      "Epoch: 002/020 | Batch 0600/1284 | Cost: 0.7611\n",
      "Epoch: 002/020 | Batch 0650/1284 | Cost: 1.0281\n",
      "Epoch: 002/020 | Batch 0700/1284 | Cost: 0.5661\n",
      "Epoch: 002/020 | Batch 0750/1284 | Cost: 1.0329\n",
      "Epoch: 002/020 | Batch 0800/1284 | Cost: 0.8230\n",
      "Epoch: 002/020 | Batch 0850/1284 | Cost: 0.5291\n",
      "Epoch: 002/020 | Batch 0900/1284 | Cost: 0.4634\n",
      "Epoch: 002/020 | Batch 0950/1284 | Cost: 0.5387\n",
      "Epoch: 002/020 | Batch 1000/1284 | Cost: 0.3229\n",
      "Epoch: 002/020 | Batch 1050/1284 | Cost: 0.8777\n",
      "Epoch: 002/020 | Batch 1100/1284 | Cost: 0.5176\n",
      "Epoch: 002/020 | Batch 1150/1284 | Cost: 0.3986\n",
      "Epoch: 002/020 | Batch 1200/1284 | Cost: 0.5860\n",
      "Epoch: 002/020 | Batch 1250/1284 | Cost: 0.6583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1284it [02:08,  9.99it/s]\n",
      "428it [00:40, 10.54it/s]\n",
      "428it [00:40, 10.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 16.20 min\n",
      "Epoch: 003/020 | Batch 0000/1284 | Cost: 0.7621\n",
      "Epoch: 003/020 | Batch 0050/1284 | Cost: 1.0084\n",
      "Epoch: 003/020 | Batch 0100/1284 | Cost: 0.5572\n",
      "Epoch: 003/020 | Batch 0150/1284 | Cost: 0.4871\n",
      "Epoch: 003/020 | Batch 0200/1284 | Cost: 0.3948\n",
      "Epoch: 003/020 | Batch 0250/1284 | Cost: 0.5541\n",
      "Epoch: 003/020 | Batch 0300/1284 | Cost: 0.5037\n",
      "Epoch: 003/020 | Batch 0350/1284 | Cost: 0.3841\n",
      "Epoch: 003/020 | Batch 0400/1284 | Cost: 0.2560\n",
      "Epoch: 003/020 | Batch 0450/1284 | Cost: 0.4980\n",
      "Epoch: 003/020 | Batch 0500/1284 | Cost: 0.4673\n",
      "Epoch: 003/020 | Batch 0550/1284 | Cost: 0.3828\n",
      "Epoch: 003/020 | Batch 0600/1284 | Cost: 0.5367\n",
      "Epoch: 003/020 | Batch 0650/1284 | Cost: 0.1563\n",
      "Epoch: 003/020 | Batch 0700/1284 | Cost: 0.4658\n",
      "Epoch: 003/020 | Batch 0750/1284 | Cost: 0.8065\n",
      "Epoch: 003/020 | Batch 0800/1284 | Cost: 0.3542\n",
      "Epoch: 003/020 | Batch 0850/1284 | Cost: 0.5669\n",
      "Epoch: 003/020 | Batch 0900/1284 | Cost: 0.2251\n",
      "Epoch: 003/020 | Batch 0950/1284 | Cost: 0.4289\n",
      "Epoch: 003/020 | Batch 1000/1284 | Cost: 0.4108\n",
      "Epoch: 003/020 | Batch 1050/1284 | Cost: 0.2464\n",
      "Epoch: 003/020 | Batch 1100/1284 | Cost: 0.3547\n",
      "Epoch: 003/020 | Batch 1150/1284 | Cost: 0.3007\n",
      "Epoch: 003/020 | Batch 1200/1284 | Cost: 0.2149\n",
      "Epoch: 003/020 | Batch 1250/1284 | Cost: 0.3396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1284it [02:08,  9.98it/s]\n",
      "428it [00:40, 10.62it/s]\n",
      "428it [00:40, 10.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 23.77 min\n",
      "Epoch: 004/020 | Batch 0000/1284 | Cost: 0.3249\n",
      "Epoch: 004/020 | Batch 0050/1284 | Cost: 0.3785\n",
      "Epoch: 004/020 | Batch 0100/1284 | Cost: 0.3090\n",
      "Epoch: 004/020 | Batch 0150/1284 | Cost: 0.3581\n",
      "Epoch: 004/020 | Batch 0200/1284 | Cost: 0.6255\n",
      "Epoch: 004/020 | Batch 0250/1284 | Cost: 0.3037\n",
      "Epoch: 004/020 | Batch 0300/1284 | Cost: 0.2664\n",
      "Epoch: 004/020 | Batch 0350/1284 | Cost: 0.1478\n",
      "Epoch: 004/020 | Batch 0400/1284 | Cost: 0.2993\n",
      "Epoch: 004/020 | Batch 0450/1284 | Cost: 0.1546\n",
      "Epoch: 004/020 | Batch 0500/1284 | Cost: 0.2511\n",
      "Epoch: 004/020 | Batch 0550/1284 | Cost: 0.1720\n",
      "Epoch: 004/020 | Batch 0600/1284 | Cost: 0.3923\n",
      "Epoch: 004/020 | Batch 0650/1284 | Cost: 0.2034\n",
      "Epoch: 004/020 | Batch 0700/1284 | Cost: 0.3683\n",
      "Epoch: 004/020 | Batch 0750/1284 | Cost: 0.2094\n",
      "Epoch: 004/020 | Batch 0800/1284 | Cost: 0.2378\n",
      "Epoch: 004/020 | Batch 0850/1284 | Cost: 0.8335\n",
      "Epoch: 004/020 | Batch 0900/1284 | Cost: 0.1392\n",
      "Epoch: 004/020 | Batch 0950/1284 | Cost: 0.2377\n",
      "Epoch: 004/020 | Batch 1000/1284 | Cost: 0.4233\n",
      "Epoch: 004/020 | Batch 1050/1284 | Cost: 0.4997\n",
      "Epoch: 004/020 | Batch 1100/1284 | Cost: 0.1153\n",
      "Epoch: 004/020 | Batch 1150/1284 | Cost: 0.1669\n",
      "Epoch: 004/020 | Batch 1200/1284 | Cost: 0.3681\n",
      "Epoch: 004/020 | Batch 1250/1284 | Cost: 0.2465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1284it [02:07, 10.10it/s]\n",
      "428it [00:40, 10.57it/s]\n",
      "428it [00:40, 10.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 31.33 min\n",
      "Epoch: 005/020 | Batch 0000/1284 | Cost: 0.1862\n",
      "Epoch: 005/020 | Batch 0050/1284 | Cost: 0.2240\n",
      "Epoch: 005/020 | Batch 0100/1284 | Cost: 0.1818\n",
      "Epoch: 005/020 | Batch 0150/1284 | Cost: 0.5085\n",
      "Epoch: 005/020 | Batch 0200/1284 | Cost: 0.3171\n",
      "Epoch: 005/020 | Batch 0250/1284 | Cost: 0.1354\n",
      "Epoch: 005/020 | Batch 0300/1284 | Cost: 0.2144\n",
      "Epoch: 005/020 | Batch 0350/1284 | Cost: 0.2266\n",
      "Epoch: 005/020 | Batch 0400/1284 | Cost: 0.6857\n",
      "Epoch: 005/020 | Batch 0450/1284 | Cost: 0.2047\n",
      "Epoch: 005/020 | Batch 0500/1284 | Cost: 0.0990\n",
      "Epoch: 005/020 | Batch 0550/1284 | Cost: 0.2109\n",
      "Epoch: 005/020 | Batch 0600/1284 | Cost: 0.2220\n",
      "Epoch: 005/020 | Batch 0650/1284 | Cost: 0.0619\n",
      "Epoch: 005/020 | Batch 0700/1284 | Cost: 0.1242\n",
      "Epoch: 005/020 | Batch 0750/1284 | Cost: 0.2689\n",
      "Epoch: 005/020 | Batch 0800/1284 | Cost: 0.0469\n",
      "Epoch: 005/020 | Batch 0850/1284 | Cost: 0.0505\n",
      "Epoch: 005/020 | Batch 0900/1284 | Cost: 0.1020\n",
      "Epoch: 005/020 | Batch 0950/1284 | Cost: 0.1343\n",
      "Epoch: 005/020 | Batch 1000/1284 | Cost: 0.2750\n",
      "Epoch: 005/020 | Batch 1050/1284 | Cost: 0.3141\n",
      "Epoch: 005/020 | Batch 1100/1284 | Cost: 0.1852\n",
      "Epoch: 005/020 | Batch 1150/1284 | Cost: 0.2401\n",
      "Epoch: 005/020 | Batch 1200/1284 | Cost: 0.3565\n",
      "Epoch: 005/020 | Batch 1250/1284 | Cost: 0.0962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1284it [02:10,  9.81it/s]\n",
      "428it [00:41, 10.37it/s]\n",
      "428it [00:41, 10.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 39.06 min\n",
      "Epoch: 006/020 | Batch 0000/1284 | Cost: 0.0849\n",
      "Epoch: 006/020 | Batch 0050/1284 | Cost: 0.2723\n",
      "Epoch: 006/020 | Batch 0100/1284 | Cost: 0.2554\n",
      "Epoch: 006/020 | Batch 0150/1284 | Cost: 0.0976\n",
      "Epoch: 006/020 | Batch 0200/1284 | Cost: 0.1160\n",
      "Epoch: 006/020 | Batch 0250/1284 | Cost: 0.2171\n",
      "Epoch: 006/020 | Batch 0300/1284 | Cost: 0.0869\n",
      "Epoch: 006/020 | Batch 0350/1284 | Cost: 0.1036\n",
      "Epoch: 006/020 | Batch 0400/1284 | Cost: 0.0573\n",
      "Epoch: 006/020 | Batch 0450/1284 | Cost: 0.1514\n",
      "Epoch: 006/020 | Batch 0500/1284 | Cost: 0.0293\n",
      "Epoch: 006/020 | Batch 0550/1284 | Cost: 0.2593\n",
      "Epoch: 006/020 | Batch 0600/1284 | Cost: 0.1931\n",
      "Epoch: 006/020 | Batch 0650/1284 | Cost: 0.2018\n",
      "Epoch: 006/020 | Batch 0700/1284 | Cost: 0.3463\n",
      "Epoch: 006/020 | Batch 0750/1284 | Cost: 0.1285\n",
      "Epoch: 006/020 | Batch 0800/1284 | Cost: 0.2038\n",
      "Epoch: 006/020 | Batch 0850/1284 | Cost: 0.1111\n",
      "Epoch: 006/020 | Batch 0900/1284 | Cost: 0.1785\n",
      "Epoch: 006/020 | Batch 0950/1284 | Cost: 0.0879\n",
      "Epoch: 006/020 | Batch 1000/1284 | Cost: 0.4031\n",
      "Epoch: 006/020 | Batch 1050/1284 | Cost: 0.2303\n",
      "Epoch: 006/020 | Batch 1100/1284 | Cost: 0.0543\n",
      "Epoch: 006/020 | Batch 1150/1284 | Cost: 0.1534\n",
      "Epoch: 006/020 | Batch 1200/1284 | Cost: 0.5428\n",
      "Epoch: 006/020 | Batch 1250/1284 | Cost: 0.2587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1284it [01:57, 10.92it/s]\n",
      "428it [00:36, 11.77it/s]\n",
      "428it [00:36, 11.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 46.24 min\n",
      "Epoch: 007/020 | Batch 0000/1284 | Cost: 0.0702\n",
      "Epoch: 007/020 | Batch 0050/1284 | Cost: 0.3181\n",
      "Epoch: 007/020 | Batch 0100/1284 | Cost: 0.1095\n",
      "Epoch: 007/020 | Batch 0150/1284 | Cost: 0.3129\n",
      "Epoch: 007/020 | Batch 0200/1284 | Cost: 0.0330\n",
      "Epoch: 007/020 | Batch 0250/1284 | Cost: 0.0921\n",
      "Epoch: 007/020 | Batch 0300/1284 | Cost: 0.0274\n",
      "Epoch: 007/020 | Batch 0350/1284 | Cost: 0.0504\n",
      "Epoch: 007/020 | Batch 0400/1284 | Cost: 0.0618\n",
      "Epoch: 007/020 | Batch 0450/1284 | Cost: 0.2028\n",
      "Epoch: 007/020 | Batch 0500/1284 | Cost: 0.1517\n",
      "Epoch: 007/020 | Batch 0550/1284 | Cost: 0.1102\n",
      "Epoch: 007/020 | Batch 0600/1284 | Cost: 0.4056\n",
      "Epoch: 007/020 | Batch 0650/1284 | Cost: 0.1662\n",
      "Epoch: 007/020 | Batch 0700/1284 | Cost: 0.0809\n",
      "Epoch: 007/020 | Batch 0750/1284 | Cost: 0.1949\n",
      "Epoch: 007/020 | Batch 0800/1284 | Cost: 0.0127\n",
      "Epoch: 007/020 | Batch 0850/1284 | Cost: 0.0199\n",
      "Epoch: 007/020 | Batch 0900/1284 | Cost: 0.0127\n",
      "Epoch: 007/020 | Batch 0950/1284 | Cost: 0.1456\n",
      "Epoch: 007/020 | Batch 1000/1284 | Cost: 0.1018\n",
      "Epoch: 007/020 | Batch 1050/1284 | Cost: 0.0386\n",
      "Epoch: 007/020 | Batch 1100/1284 | Cost: 0.2025\n",
      "Epoch: 007/020 | Batch 1150/1284 | Cost: 0.1479\n",
      "Epoch: 007/020 | Batch 1200/1284 | Cost: 0.1265\n",
      "Epoch: 007/020 | Batch 1250/1284 | Cost: 0.2532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1284it [01:55, 11.08it/s]\n",
      "428it [00:39, 10.95it/s]\n",
      "428it [00:39, 10.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 53.37 min\n",
      "Epoch: 008/020 | Batch 0000/1284 | Cost: 0.1306\n",
      "Epoch: 008/020 | Batch 0050/1284 | Cost: 0.2516\n",
      "Epoch: 008/020 | Batch 0100/1284 | Cost: 0.0365\n",
      "Epoch: 008/020 | Batch 0150/1284 | Cost: 0.0162\n",
      "Epoch: 008/020 | Batch 0200/1284 | Cost: 0.2405\n",
      "Epoch: 008/020 | Batch 0250/1284 | Cost: 0.1442\n",
      "Epoch: 008/020 | Batch 0300/1284 | Cost: 0.0915\n",
      "Epoch: 008/020 | Batch 0350/1284 | Cost: 0.1776\n",
      "Epoch: 008/020 | Batch 0400/1284 | Cost: 0.0171\n",
      "Epoch: 008/020 | Batch 0450/1284 | Cost: 0.1440\n",
      "Epoch: 008/020 | Batch 0500/1284 | Cost: 0.2032\n",
      "Epoch: 008/020 | Batch 0550/1284 | Cost: 0.0694\n",
      "Epoch: 008/020 | Batch 0600/1284 | Cost: 0.1180\n",
      "Epoch: 008/020 | Batch 0650/1284 | Cost: 0.0135\n",
      "Epoch: 008/020 | Batch 0700/1284 | Cost: 0.1228\n",
      "Epoch: 008/020 | Batch 0750/1284 | Cost: 0.0130\n",
      "Epoch: 008/020 | Batch 0800/1284 | Cost: 0.0053\n",
      "Epoch: 008/020 | Batch 0850/1284 | Cost: 0.3276\n",
      "Epoch: 008/020 | Batch 0900/1284 | Cost: 0.1128\n",
      "Epoch: 008/020 | Batch 0950/1284 | Cost: 0.2027\n",
      "Epoch: 008/020 | Batch 1000/1284 | Cost: 0.1998\n",
      "Epoch: 008/020 | Batch 1050/1284 | Cost: 0.0547\n",
      "Epoch: 008/020 | Batch 1100/1284 | Cost: 0.2335\n",
      "Epoch: 008/020 | Batch 1150/1284 | Cost: 0.0820\n",
      "Epoch: 008/020 | Batch 1200/1284 | Cost: 0.1159\n",
      "Epoch: 008/020 | Batch 1250/1284 | Cost: 0.1405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1284it [01:55, 11.12it/s]\n",
      "428it [00:36, 11.74it/s]\n",
      "428it [00:36, 11.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 60.39 min\n",
      "Epoch: 009/020 | Batch 0000/1284 | Cost: 0.0526\n",
      "Epoch: 009/020 | Batch 0050/1284 | Cost: 0.1675\n",
      "Epoch: 009/020 | Batch 0100/1284 | Cost: 0.1328\n",
      "Epoch: 009/020 | Batch 0150/1284 | Cost: 0.1561\n",
      "Epoch: 009/020 | Batch 0200/1284 | Cost: 0.1184\n",
      "Epoch: 009/020 | Batch 0250/1284 | Cost: 0.1359\n",
      "Epoch: 009/020 | Batch 0300/1284 | Cost: 0.0143\n",
      "Epoch: 009/020 | Batch 0350/1284 | Cost: 0.0222\n",
      "Epoch: 009/020 | Batch 0400/1284 | Cost: 0.0491\n",
      "Epoch: 009/020 | Batch 0450/1284 | Cost: 0.0232\n",
      "Epoch: 009/020 | Batch 0500/1284 | Cost: 0.0706\n",
      "Epoch: 009/020 | Batch 0550/1284 | Cost: 0.1514\n",
      "Epoch: 009/020 | Batch 0600/1284 | Cost: 0.1781\n",
      "Epoch: 009/020 | Batch 0650/1284 | Cost: 0.0169\n",
      "Epoch: 009/020 | Batch 0700/1284 | Cost: 0.0658\n",
      "Epoch: 009/020 | Batch 0750/1284 | Cost: 0.0789\n",
      "Epoch: 009/020 | Batch 0800/1284 | Cost: 0.0355\n",
      "Epoch: 009/020 | Batch 0850/1284 | Cost: 0.1059\n",
      "Epoch: 009/020 | Batch 0900/1284 | Cost: 0.2115\n",
      "Epoch: 009/020 | Batch 0950/1284 | Cost: 0.1128\n",
      "Epoch: 009/020 | Batch 1000/1284 | Cost: 0.1093\n",
      "Epoch: 009/020 | Batch 1050/1284 | Cost: 0.1204\n",
      "Epoch: 009/020 | Batch 1100/1284 | Cost: 0.0091\n",
      "Epoch: 009/020 | Batch 1150/1284 | Cost: 0.1755\n",
      "Epoch: 009/020 | Batch 1200/1284 | Cost: 0.0802\n",
      "Epoch: 009/020 | Batch 1250/1284 | Cost: 0.1649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1284it [01:56, 11.05it/s]\n",
      "428it [00:36, 11.76it/s]\n",
      "428it [00:36, 11.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 67.44 min\n",
      "Epoch: 010/020 | Batch 0000/1284 | Cost: 0.0655\n",
      "Epoch: 010/020 | Batch 0050/1284 | Cost: 0.0308\n",
      "Epoch: 010/020 | Batch 0100/1284 | Cost: 0.0674\n",
      "Epoch: 010/020 | Batch 0150/1284 | Cost: 0.0869\n",
      "Epoch: 010/020 | Batch 0200/1284 | Cost: 0.1852\n",
      "Epoch: 010/020 | Batch 0250/1284 | Cost: 0.0578\n",
      "Epoch: 010/020 | Batch 0300/1284 | Cost: 0.0904\n",
      "Epoch: 010/020 | Batch 0350/1284 | Cost: 0.0178\n",
      "Epoch: 010/020 | Batch 0400/1284 | Cost: 0.0300\n",
      "Epoch: 010/020 | Batch 0450/1284 | Cost: 0.1328\n",
      "Epoch: 010/020 | Batch 0500/1284 | Cost: 0.0339\n",
      "Epoch: 010/020 | Batch 0550/1284 | Cost: 0.0614\n",
      "Epoch: 010/020 | Batch 0600/1284 | Cost: 0.0375\n",
      "Epoch: 010/020 | Batch 0650/1284 | Cost: 0.0056\n",
      "Epoch: 010/020 | Batch 0700/1284 | Cost: 0.1356\n",
      "Epoch: 010/020 | Batch 0750/1284 | Cost: 0.0768\n",
      "Epoch: 010/020 | Batch 0800/1284 | Cost: 0.0971\n",
      "Epoch: 010/020 | Batch 0850/1284 | Cost: 0.0850\n",
      "Epoch: 010/020 | Batch 0900/1284 | Cost: 0.1391\n",
      "Epoch: 010/020 | Batch 0950/1284 | Cost: 0.0113\n",
      "Epoch: 010/020 | Batch 1000/1284 | Cost: 0.0353\n",
      "Epoch: 010/020 | Batch 1050/1284 | Cost: 0.0539\n",
      "Epoch: 010/020 | Batch 1100/1284 | Cost: 0.0911\n",
      "Epoch: 010/020 | Batch 1150/1284 | Cost: 0.0584\n",
      "Epoch: 010/020 | Batch 1200/1284 | Cost: 0.2218\n",
      "Epoch: 010/020 | Batch 1250/1284 | Cost: 0.2857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1284it [01:55, 11.09it/s]\n",
      "428it [00:36, 11.67it/s]\n",
      "428it [00:36, 11.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 74.48 min\n",
      "Epoch: 011/020 | Batch 0000/1284 | Cost: 0.0767\n",
      "Epoch: 011/020 | Batch 0050/1284 | Cost: 0.0969\n",
      "Epoch: 011/020 | Batch 0100/1284 | Cost: 0.0838\n",
      "Epoch: 011/020 | Batch 0150/1284 | Cost: 0.0180\n",
      "Epoch: 011/020 | Batch 0200/1284 | Cost: 0.0363\n",
      "Epoch: 011/020 | Batch 0250/1284 | Cost: 0.0427\n",
      "Epoch: 011/020 | Batch 0300/1284 | Cost: 0.1163\n",
      "Epoch: 011/020 | Batch 0350/1284 | Cost: 0.0315\n",
      "Epoch: 011/020 | Batch 0400/1284 | Cost: 0.0038\n",
      "Epoch: 011/020 | Batch 0450/1284 | Cost: 0.0067\n",
      "Epoch: 011/020 | Batch 0500/1284 | Cost: 0.0181\n",
      "Epoch: 011/020 | Batch 0550/1284 | Cost: 0.0042\n",
      "Epoch: 011/020 | Batch 0600/1284 | Cost: 0.2439\n",
      "Epoch: 011/020 | Batch 0650/1284 | Cost: 0.1200\n",
      "Epoch: 011/020 | Batch 0700/1284 | Cost: 0.0029\n",
      "Epoch: 011/020 | Batch 0750/1284 | Cost: 0.0364\n",
      "Epoch: 011/020 | Batch 0800/1284 | Cost: 0.4341\n",
      "Epoch: 011/020 | Batch 0850/1284 | Cost: 0.1179\n",
      "Epoch: 011/020 | Batch 0900/1284 | Cost: 0.0270\n",
      "Epoch: 011/020 | Batch 0950/1284 | Cost: 0.0027\n",
      "Epoch: 011/020 | Batch 1000/1284 | Cost: 0.0887\n",
      "Epoch: 011/020 | Batch 1050/1284 | Cost: 0.0526\n",
      "Epoch: 011/020 | Batch 1100/1284 | Cost: 0.0127\n",
      "Epoch: 011/020 | Batch 1150/1284 | Cost: 0.1479\n",
      "Epoch: 011/020 | Batch 1200/1284 | Cost: 0.0350\n",
      "Epoch: 011/020 | Batch 1250/1284 | Cost: 0.0027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1284it [01:56, 11.06it/s]\n",
      "428it [00:36, 11.85it/s]\n",
      "428it [00:36, 11.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 81.52 min\n",
      "Epoch: 012/020 | Batch 0000/1284 | Cost: 0.0549\n",
      "Epoch: 012/020 | Batch 0050/1284 | Cost: 0.0740\n",
      "Epoch: 012/020 | Batch 0100/1284 | Cost: 0.1096\n",
      "Epoch: 012/020 | Batch 0150/1284 | Cost: 0.2158\n",
      "Epoch: 012/020 | Batch 0200/1284 | Cost: 0.0264\n",
      "Epoch: 012/020 | Batch 0250/1284 | Cost: 0.0895\n",
      "Epoch: 012/020 | Batch 0300/1284 | Cost: 0.0248\n",
      "Epoch: 012/020 | Batch 0350/1284 | Cost: 0.0113\n",
      "Epoch: 012/020 | Batch 0400/1284 | Cost: 0.0056\n",
      "Epoch: 012/020 | Batch 0450/1284 | Cost: 0.1463\n",
      "Epoch: 012/020 | Batch 0500/1284 | Cost: 0.0107\n",
      "Epoch: 012/020 | Batch 0550/1284 | Cost: 0.0321\n",
      "Epoch: 012/020 | Batch 0600/1284 | Cost: 0.1168\n",
      "Epoch: 012/020 | Batch 0650/1284 | Cost: 0.0371\n",
      "Epoch: 012/020 | Batch 0700/1284 | Cost: 0.0031\n",
      "Epoch: 012/020 | Batch 0750/1284 | Cost: 0.1276\n",
      "Epoch: 012/020 | Batch 0800/1284 | Cost: 0.0808\n",
      "Epoch: 012/020 | Batch 0850/1284 | Cost: 0.1123\n",
      "Epoch: 012/020 | Batch 0900/1284 | Cost: 0.0400\n",
      "Epoch: 012/020 | Batch 0950/1284 | Cost: 0.0627\n",
      "Epoch: 012/020 | Batch 1000/1284 | Cost: 0.0195\n",
      "Epoch: 012/020 | Batch 1050/1284 | Cost: 0.0044\n",
      "Epoch: 012/020 | Batch 1100/1284 | Cost: 0.1304\n",
      "Epoch: 012/020 | Batch 1150/1284 | Cost: 0.2673\n",
      "Epoch: 012/020 | Batch 1200/1284 | Cost: 0.1583\n",
      "Epoch: 012/020 | Batch 1250/1284 | Cost: 0.1347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1284it [01:55, 11.10it/s]\n",
      "428it [00:36, 11.83it/s]\n",
      "428it [00:36, 11.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 88.54 min\n",
      "Epoch: 013/020 | Batch 0000/1284 | Cost: 0.2305\n",
      "Epoch: 013/020 | Batch 0050/1284 | Cost: 0.0128\n",
      "Epoch: 013/020 | Batch 0100/1284 | Cost: 0.1252\n",
      "Epoch: 013/020 | Batch 0150/1284 | Cost: 0.0709\n",
      "Epoch: 013/020 | Batch 0200/1284 | Cost: 0.0239\n",
      "Epoch: 013/020 | Batch 0250/1284 | Cost: 0.0047\n",
      "Epoch: 013/020 | Batch 0300/1284 | Cost: 0.0220\n",
      "Epoch: 013/020 | Batch 0350/1284 | Cost: 0.1010\n",
      "Epoch: 013/020 | Batch 0400/1284 | Cost: 0.1359\n",
      "Epoch: 013/020 | Batch 0450/1284 | Cost: 0.1502\n",
      "Epoch: 013/020 | Batch 0500/1284 | Cost: 0.0531\n",
      "Epoch: 013/020 | Batch 0550/1284 | Cost: 0.1427\n",
      "Epoch: 013/020 | Batch 0600/1284 | Cost: 0.0310\n",
      "Epoch: 013/020 | Batch 0650/1284 | Cost: 0.0402\n",
      "Epoch: 013/020 | Batch 0700/1284 | Cost: 0.0690\n",
      "Epoch: 013/020 | Batch 0750/1284 | Cost: 0.0040\n",
      "Epoch: 013/020 | Batch 0800/1284 | Cost: 0.0167\n",
      "Epoch: 013/020 | Batch 0850/1284 | Cost: 0.0644\n",
      "Epoch: 013/020 | Batch 0900/1284 | Cost: 0.0072\n",
      "Epoch: 013/020 | Batch 0950/1284 | Cost: 0.0124\n",
      "Epoch: 013/020 | Batch 1000/1284 | Cost: 0.1885\n",
      "Epoch: 013/020 | Batch 1050/1284 | Cost: 0.1872\n",
      "Epoch: 013/020 | Batch 1100/1284 | Cost: 0.0122\n",
      "Epoch: 013/020 | Batch 1150/1284 | Cost: 0.0586\n",
      "Epoch: 013/020 | Batch 1200/1284 | Cost: 0.1848\n",
      "Epoch: 013/020 | Batch 1250/1284 | Cost: 0.0378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1284it [01:56, 11.03it/s]\n",
      "428it [00:41, 10.35it/s]\n",
      "428it [00:36, 11.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 95.72 min\n",
      "Epoch: 014/020 | Batch 0000/1284 | Cost: 0.0048\n",
      "Epoch: 014/020 | Batch 0050/1284 | Cost: 0.0053\n",
      "Epoch: 014/020 | Batch 0100/1284 | Cost: 0.0475\n",
      "Epoch: 014/020 | Batch 0150/1284 | Cost: 0.0250\n",
      "Epoch: 014/020 | Batch 0200/1284 | Cost: 0.0225\n",
      "Epoch: 014/020 | Batch 0250/1284 | Cost: 0.1615\n",
      "Epoch: 014/020 | Batch 0300/1284 | Cost: 0.0526\n",
      "Epoch: 014/020 | Batch 0350/1284 | Cost: 0.0040\n",
      "Epoch: 014/020 | Batch 0400/1284 | Cost: 0.2202\n",
      "Epoch: 014/020 | Batch 0450/1284 | Cost: 0.0095\n",
      "Epoch: 014/020 | Batch 0500/1284 | Cost: 0.0168\n",
      "Epoch: 014/020 | Batch 0550/1284 | Cost: 0.0087\n",
      "Epoch: 014/020 | Batch 0600/1284 | Cost: 0.1243\n",
      "Epoch: 014/020 | Batch 0650/1284 | Cost: 0.1112\n",
      "Epoch: 014/020 | Batch 0700/1284 | Cost: 0.0838\n",
      "Epoch: 014/020 | Batch 0750/1284 | Cost: 0.1928\n",
      "Epoch: 014/020 | Batch 0800/1284 | Cost: 0.0667\n",
      "Epoch: 014/020 | Batch 0850/1284 | Cost: 0.0717\n",
      "Epoch: 014/020 | Batch 0900/1284 | Cost: 0.0549\n",
      "Epoch: 014/020 | Batch 0950/1284 | Cost: 0.0793\n",
      "Epoch: 014/020 | Batch 1000/1284 | Cost: 0.0670\n",
      "Epoch: 014/020 | Batch 1050/1284 | Cost: 0.0394\n",
      "Epoch: 014/020 | Batch 1100/1284 | Cost: 0.1861\n",
      "Epoch: 014/020 | Batch 1150/1284 | Cost: 0.0578\n",
      "Epoch: 014/020 | Batch 1200/1284 | Cost: 0.0089\n",
      "Epoch: 014/020 | Batch 1250/1284 | Cost: 0.0084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1284it [02:13,  9.60it/s]\n",
      "428it [00:46,  9.22it/s]\n",
      "428it [00:45,  9.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 103.44 min\n",
      "Epoch: 015/020 | Batch 0000/1284 | Cost: 0.0668\n",
      "Epoch: 015/020 | Batch 0050/1284 | Cost: 0.0470\n",
      "Epoch: 015/020 | Batch 0100/1284 | Cost: 0.1366\n",
      "Epoch: 015/020 | Batch 0150/1284 | Cost: 0.0569\n",
      "Epoch: 015/020 | Batch 0200/1284 | Cost: 0.0466\n",
      "Epoch: 015/020 | Batch 0250/1284 | Cost: 0.1084\n",
      "Epoch: 015/020 | Batch 0300/1284 | Cost: 0.0515\n",
      "Epoch: 015/020 | Batch 0350/1284 | Cost: 0.0021\n",
      "Epoch: 015/020 | Batch 0400/1284 | Cost: 0.1268\n",
      "Epoch: 015/020 | Batch 0450/1284 | Cost: 0.0843\n",
      "Epoch: 015/020 | Batch 0500/1284 | Cost: 0.0657\n",
      "Epoch: 015/020 | Batch 0550/1284 | Cost: 0.0110\n",
      "Epoch: 015/020 | Batch 0600/1284 | Cost: 0.0030\n",
      "Epoch: 015/020 | Batch 0650/1284 | Cost: 0.0081\n",
      "Epoch: 015/020 | Batch 0700/1284 | Cost: 0.0163\n",
      "Epoch: 015/020 | Batch 0750/1284 | Cost: 0.0479\n",
      "Epoch: 015/020 | Batch 0800/1284 | Cost: 0.0372\n",
      "Epoch: 015/020 | Batch 0850/1284 | Cost: 0.1377\n",
      "Epoch: 015/020 | Batch 0900/1284 | Cost: 0.1623\n",
      "Epoch: 015/020 | Batch 0950/1284 | Cost: 0.0755\n",
      "Epoch: 015/020 | Batch 1000/1284 | Cost: 0.0695\n",
      "Epoch: 015/020 | Batch 1050/1284 | Cost: 0.1560\n",
      "Epoch: 015/020 | Batch 1100/1284 | Cost: 0.1008\n",
      "Epoch: 015/020 | Batch 1150/1284 | Cost: 0.0154\n",
      "Epoch: 015/020 | Batch 1200/1284 | Cost: 0.0309\n",
      "Epoch: 015/020 | Batch 1250/1284 | Cost: 0.1280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1284it [03:04,  6.94it/s]\n",
      "428it [00:38, 11.06it/s]\n",
      "428it [00:37, 11.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 111.92 min\n",
      "Epoch: 016/020 | Batch 0000/1284 | Cost: 0.0941\n",
      "Epoch: 016/020 | Batch 0050/1284 | Cost: 0.0690\n",
      "Epoch: 016/020 | Batch 0100/1284 | Cost: 0.0025\n",
      "Epoch: 016/020 | Batch 0150/1284 | Cost: 0.2844\n",
      "Epoch: 016/020 | Batch 0200/1284 | Cost: 0.0181\n",
      "Epoch: 016/020 | Batch 0250/1284 | Cost: 0.0026\n",
      "Epoch: 016/020 | Batch 0300/1284 | Cost: 0.0058\n",
      "Epoch: 016/020 | Batch 0350/1284 | Cost: 0.0887\n",
      "Epoch: 016/020 | Batch 0400/1284 | Cost: 0.0242\n",
      "Epoch: 016/020 | Batch 0450/1284 | Cost: 0.0023\n",
      "Epoch: 016/020 | Batch 0500/1284 | Cost: 0.0050\n",
      "Epoch: 016/020 | Batch 0550/1284 | Cost: 0.1647\n",
      "Epoch: 016/020 | Batch 0600/1284 | Cost: 0.0117\n",
      "Epoch: 016/020 | Batch 0650/1284 | Cost: 0.1609\n",
      "Epoch: 016/020 | Batch 0700/1284 | Cost: 0.0100\n",
      "Epoch: 016/020 | Batch 0750/1284 | Cost: 0.0523\n",
      "Epoch: 016/020 | Batch 0800/1284 | Cost: 0.0073\n",
      "Epoch: 016/020 | Batch 0850/1284 | Cost: 0.0112\n",
      "Epoch: 016/020 | Batch 0900/1284 | Cost: 0.3612\n",
      "Epoch: 016/020 | Batch 0950/1284 | Cost: 0.0180\n",
      "Epoch: 016/020 | Batch 1000/1284 | Cost: 0.0007\n",
      "Epoch: 016/020 | Batch 1050/1284 | Cost: 0.0684\n",
      "Epoch: 016/020 | Batch 1100/1284 | Cost: 0.0055\n",
      "Epoch: 016/020 | Batch 1150/1284 | Cost: 0.0871\n",
      "Epoch: 016/020 | Batch 1200/1284 | Cost: 0.0301\n",
      "Epoch: 016/020 | Batch 1250/1284 | Cost: 0.0505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1284it [01:56, 11.06it/s]\n",
      "428it [00:36, 11.75it/s]\n",
      "428it [00:36, 11.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 119.12 min\n",
      "Epoch: 017/020 | Batch 0000/1284 | Cost: 0.0031\n",
      "Epoch: 017/020 | Batch 0050/1284 | Cost: 0.0397\n",
      "Epoch: 017/020 | Batch 0100/1284 | Cost: 0.0052\n",
      "Epoch: 017/020 | Batch 0150/1284 | Cost: 0.0182\n",
      "Epoch: 017/020 | Batch 0200/1284 | Cost: 0.1997\n",
      "Epoch: 017/020 | Batch 0250/1284 | Cost: 0.0061\n",
      "Epoch: 017/020 | Batch 0300/1284 | Cost: 0.0022\n",
      "Epoch: 017/020 | Batch 0350/1284 | Cost: 0.0455\n",
      "Epoch: 017/020 | Batch 0400/1284 | Cost: 0.0215\n",
      "Epoch: 017/020 | Batch 0450/1284 | Cost: 0.0498\n",
      "Epoch: 017/020 | Batch 0500/1284 | Cost: 0.0389\n",
      "Epoch: 017/020 | Batch 0550/1284 | Cost: 0.0031\n",
      "Epoch: 017/020 | Batch 0600/1284 | Cost: 0.2566\n",
      "Epoch: 017/020 | Batch 0650/1284 | Cost: 0.0073\n",
      "Epoch: 017/020 | Batch 0700/1284 | Cost: 0.0229\n",
      "Epoch: 017/020 | Batch 0750/1284 | Cost: 0.0612\n",
      "Epoch: 017/020 | Batch 0800/1284 | Cost: 0.0310\n",
      "Epoch: 017/020 | Batch 0850/1284 | Cost: 0.0859\n",
      "Epoch: 017/020 | Batch 0900/1284 | Cost: 0.1291\n",
      "Epoch: 017/020 | Batch 0950/1284 | Cost: 0.0401\n",
      "Epoch: 017/020 | Batch 1000/1284 | Cost: 0.0213\n",
      "Epoch: 017/020 | Batch 1050/1284 | Cost: 0.0353\n",
      "Epoch: 017/020 | Batch 1100/1284 | Cost: 0.0096\n",
      "Epoch: 017/020 | Batch 1150/1284 | Cost: 0.0097\n",
      "Epoch: 017/020 | Batch 1200/1284 | Cost: 0.0540\n",
      "Epoch: 017/020 | Batch 1250/1284 | Cost: 0.0343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1284it [01:57, 10.92it/s]\n",
      "428it [00:37, 11.54it/s]\n",
      "428it [00:36, 11.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 126.22 min\n",
      "Epoch: 018/020 | Batch 0000/1284 | Cost: 0.0189\n",
      "Epoch: 018/020 | Batch 0050/1284 | Cost: 0.0020\n",
      "Epoch: 018/020 | Batch 0100/1284 | Cost: 0.0289\n",
      "Epoch: 018/020 | Batch 0150/1284 | Cost: 0.0047\n",
      "Epoch: 018/020 | Batch 0200/1284 | Cost: 0.0345\n",
      "Epoch: 018/020 | Batch 0250/1284 | Cost: 0.0991\n",
      "Epoch: 018/020 | Batch 0300/1284 | Cost: 0.0402\n",
      "Epoch: 018/020 | Batch 0350/1284 | Cost: 0.0028\n",
      "Epoch: 018/020 | Batch 0400/1284 | Cost: 0.0017\n",
      "Epoch: 018/020 | Batch 0450/1284 | Cost: 0.0127\n",
      "Epoch: 018/020 | Batch 0500/1284 | Cost: 0.0112\n",
      "Epoch: 018/020 | Batch 0550/1284 | Cost: 0.2700\n",
      "Epoch: 018/020 | Batch 0600/1284 | Cost: 0.0457\n",
      "Epoch: 018/020 | Batch 0650/1284 | Cost: 0.0052\n",
      "Epoch: 018/020 | Batch 0700/1284 | Cost: 0.0111\n",
      "Epoch: 018/020 | Batch 0750/1284 | Cost: 0.0092\n",
      "Epoch: 018/020 | Batch 0800/1284 | Cost: 0.0016\n",
      "Epoch: 018/020 | Batch 0850/1284 | Cost: 0.0393\n",
      "Epoch: 018/020 | Batch 0900/1284 | Cost: 0.0019\n",
      "Epoch: 018/020 | Batch 0950/1284 | Cost: 0.0426\n",
      "Epoch: 018/020 | Batch 1000/1284 | Cost: 0.0324\n",
      "Epoch: 018/020 | Batch 1050/1284 | Cost: 0.0735\n",
      "Epoch: 018/020 | Batch 1100/1284 | Cost: 0.0021\n",
      "Epoch: 018/020 | Batch 1150/1284 | Cost: 0.0447\n",
      "Epoch: 018/020 | Batch 1200/1284 | Cost: 0.0235\n",
      "Epoch: 018/020 | Batch 1250/1284 | Cost: 0.0422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1284it [01:56, 10.99it/s]\n",
      "428it [00:36, 11.70it/s]\n",
      "428it [00:36, 11.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 133.31 min\n",
      "Epoch: 019/020 | Batch 0000/1284 | Cost: 0.0181\n",
      "Epoch: 019/020 | Batch 0050/1284 | Cost: 0.0015\n",
      "Epoch: 019/020 | Batch 0100/1284 | Cost: 0.0021\n",
      "Epoch: 019/020 | Batch 0150/1284 | Cost: 0.0456\n",
      "Epoch: 019/020 | Batch 0200/1284 | Cost: 0.0706\n",
      "Epoch: 019/020 | Batch 0250/1284 | Cost: 0.0017\n",
      "Epoch: 019/020 | Batch 0300/1284 | Cost: 0.0756\n",
      "Epoch: 019/020 | Batch 0350/1284 | Cost: 0.1165\n",
      "Epoch: 019/020 | Batch 0400/1284 | Cost: 0.0068\n",
      "Epoch: 019/020 | Batch 0450/1284 | Cost: 0.0769\n",
      "Epoch: 019/020 | Batch 0500/1284 | Cost: 0.0184\n",
      "Epoch: 019/020 | Batch 0550/1284 | Cost: 0.1105\n",
      "Epoch: 019/020 | Batch 0600/1284 | Cost: 0.0662\n",
      "Epoch: 019/020 | Batch 0650/1284 | Cost: 0.0307\n",
      "Epoch: 019/020 | Batch 0700/1284 | Cost: 0.0350\n",
      "Epoch: 019/020 | Batch 0750/1284 | Cost: 0.0009\n",
      "Epoch: 019/020 | Batch 0800/1284 | Cost: 0.0054\n",
      "Epoch: 019/020 | Batch 0850/1284 | Cost: 0.0028\n",
      "Epoch: 019/020 | Batch 0900/1284 | Cost: 0.0037\n",
      "Epoch: 019/020 | Batch 0950/1284 | Cost: 0.0382\n",
      "Epoch: 019/020 | Batch 1000/1284 | Cost: 0.0229\n",
      "Epoch: 019/020 | Batch 1050/1284 | Cost: 0.0433\n",
      "Epoch: 019/020 | Batch 1100/1284 | Cost: 0.0126\n",
      "Epoch: 019/020 | Batch 1150/1284 | Cost: 0.0083\n",
      "Epoch: 019/020 | Batch 1200/1284 | Cost: 0.0019\n",
      "Epoch: 019/020 | Batch 1250/1284 | Cost: 0.0577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1284it [01:56, 11.04it/s]\n",
      "428it [00:36, 11.65it/s]\n",
      "428it [00:36, 11.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 140.37 min\n",
      "Epoch: 020/020 | Batch 0000/1284 | Cost: 0.0065\n",
      "Epoch: 020/020 | Batch 0050/1284 | Cost: 0.0028\n",
      "Epoch: 020/020 | Batch 0100/1284 | Cost: 0.0031\n",
      "Epoch: 020/020 | Batch 0150/1284 | Cost: 0.0479\n",
      "Epoch: 020/020 | Batch 0200/1284 | Cost: 0.0417\n",
      "Epoch: 020/020 | Batch 0250/1284 | Cost: 0.0278\n",
      "Epoch: 020/020 | Batch 0300/1284 | Cost: 0.0433\n",
      "Epoch: 020/020 | Batch 0350/1284 | Cost: 0.0093\n",
      "Epoch: 020/020 | Batch 0400/1284 | Cost: 0.1345\n",
      "Epoch: 020/020 | Batch 0450/1284 | Cost: 0.1095\n",
      "Epoch: 020/020 | Batch 0500/1284 | Cost: 0.1126\n",
      "Epoch: 020/020 | Batch 0550/1284 | Cost: 0.0044\n",
      "Epoch: 020/020 | Batch 0600/1284 | Cost: 0.2095\n",
      "Epoch: 020/020 | Batch 0650/1284 | Cost: 0.0294\n",
      "Epoch: 020/020 | Batch 0700/1284 | Cost: 0.0087\n",
      "Epoch: 020/020 | Batch 0750/1284 | Cost: 0.1749\n",
      "Epoch: 020/020 | Batch 0800/1284 | Cost: 0.3778\n",
      "Epoch: 020/020 | Batch 0850/1284 | Cost: 0.0345\n",
      "Epoch: 020/020 | Batch 0900/1284 | Cost: 0.0151\n",
      "Epoch: 020/020 | Batch 0950/1284 | Cost: 0.0137\n",
      "Epoch: 020/020 | Batch 1000/1284 | Cost: 0.0059\n",
      "Epoch: 020/020 | Batch 1050/1284 | Cost: 0.0313\n",
      "Epoch: 020/020 | Batch 1100/1284 | Cost: 0.0520\n",
      "Epoch: 020/020 | Batch 1150/1284 | Cost: 0.0055\n",
      "Epoch: 020/020 | Batch 1200/1284 | Cost: 0.0073\n",
      "Epoch: 020/020 | Batch 1250/1284 | Cost: 0.0523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1284it [01:55, 11.07it/s]\n",
      "428it [00:36, 11.77it/s]\n",
      "428it [00:36, 11.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 147.40 min\n",
      "Total Training Time: 147.40 min\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    \n",
    "    model.train()\n",
    "    losses = []\n",
    "    for batch_idx, (features, targets) in enumerate(train_loader):\n",
    "        \n",
    "        features = features.to(DEVICE)\n",
    "        targets = targets.to(DEVICE)\n",
    "        class_weights = class_weights.to(DEVICE)\n",
    "            \n",
    "        ### FORWARD AND BACK PROP\n",
    "        logits, probas = model(features)\n",
    "        loss = F.cross_entropy(logits, targets)\n",
    "        losses.append(loss)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        ### UPDATE MODEL PARAMETERS\n",
    "        optimizer.step()\n",
    "        \n",
    "        ### LOGGING\n",
    "        if not batch_idx % 50:\n",
    "            print ('Epoch: %03d/%03d | Batch %04d/%04d | Cost: %.4f' \n",
    "                   %(epoch+1, NUM_EPOCHS, batch_idx,\n",
    "                     len(train_loader), loss))\n",
    "    \n",
    "            mean_loss = sum(losses) / len(losses)\n",
    "            with open(f'CV_data/models/{model_name}-{LEARNING_RATE}-train-loss.csv', 'a') as fp:\n",
    "                fp.write(f\"{epoch+1}, {batch_idx}, {mean_loss}\\n\")\n",
    "            losses.clear()\n",
    "\n",
    "\n",
    "    model.eval()\n",
    "    with torch.set_grad_enabled(False): # save memory during inference\n",
    "        compute_accuracy(model, train_loader, device=DEVICE, mode=\"train\")\n",
    "        compute_loss(model, val_loader, class_weights, device=DEVICE, mode=\"val\")\n",
    "        compute_accuracy(model, val_loader, device=DEVICE, mode=\"val\")\n",
    "    \n",
    "    file_path = f'CV_data/models/{model_name}-{LEARNING_RATE}-epoch{epoch+1}.pth'\n",
    "    torch.save(model.state_dict(), file_path)\n",
    "        \n",
    "    print('Time elapsed: %.2f min' % ((time.time() - start_time)/60))\n",
    "    \n",
    "    \n",
    "    \n",
    "print('Total Training Time: %.2f min' % ((time.time() - start_time)/60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "paaeEQHQj5xC"
   },
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AvgPool2d(kernel_size=7, stride=1, padding=0)\n",
       "  (fc): Linear(in_features=2048, out_features=66, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE = \"cuda:0\"\n",
    "device = torch.device(DEVICE)\n",
    "\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "model_weights = torch.load(f\"CV_data/models/{model_name}-{LEARNING_RATE}-epoch20.pth\", map_location=torch.device('cpu'))\n",
    "\n",
    "model = resnet50(NUM_CLASSES) \n",
    "\n",
    "# Loading the weights to the model\n",
    "model.load_state_dict(model_weights)\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "\n",
    "y_pred = []\n",
    "y_true = []\n",
    "\n",
    "model.eval()\n",
    "with torch.set_grad_enabled(False):\n",
    "    for inputs, labels in test_loader:\n",
    "            inputs = inputs.to(DEVICE)\n",
    "            _, classes = model(inputs) # Feed Network\n",
    "\n",
    "            output = (torch.max(torch.exp(classes), 1)[1]).data.cpu().numpy()\n",
    "            y_pred.extend(output) # Save Prediction\n",
    "\n",
    "            labels = labels.data.cpu().numpy()\n",
    "            y_true.extend(labels) # Save Truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Build confusion matrix\n",
    "cf_matrix = confusion_matrix(y_true, y_pred)\n",
    "classes = dataset.class_to_idx.keys()\n",
    "df_cm = pd.DataFrame(cf_matrix / np.sum(cf_matrix, axis=1)[:, None], index = [i for i in classes],\n",
    "                     columns = [i for i in classes])\n",
    "plt.figure(figsize=(30, 25))\n",
    "sn.heatmap(df_cm, annot=True)\n",
    "plt.savefig(f'CV_data/conf_matrix/{model_name}-output.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "\n",
    "y_pred = []\n",
    "y_true = []\n",
    "\n",
    "model.eval()\n",
    "with torch.set_grad_enabled(False):\n",
    "    for inputs, labels in test_loader:\n",
    "            inputs = inputs.to(DEVICE)\n",
    "            _, classes = model(inputs) # Feed Network\n",
    "\n",
    "            output = (torch.max(torch.exp(classes), 1)[1]).data.cpu().numpy()\n",
    "            y_pred.extend(output) # Save Prediction\n",
    "\n",
    "            labels = labels.data.cpu().numpy()\n",
    "            y_true.extend(labels) # Save Truth\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Build confusion matrix\n",
    "cf_matrix = confusion_matrix(y_true, y_pred)\n",
    "classes = dataset.class_to_idx.keys()\n",
    "df_cm = pd.DataFrame(cf_matrix / np.sum(cf_matrix, axis=1)[:, None], index = [i for i in classes],\n",
    "                     columns = [i for i in classes])\n",
    "plt.figure(figsize=(30, 25))\n",
    "sn.heatmap(df_cm, annot=True)\n",
    "plt.savefig(f'CV_data/conf_matrix/{model_name}-output.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_idx, (features, targets) in enumerate(test_loader):\n",
    "\n",
    "    features = features\n",
    "    targets = targets\n",
    "    break\n",
    "\n",
    "NUM_IMG = 4\n",
    "fig, axs = plt.subplots(1, NUM_IMG)\n",
    "imgs = []\n",
    "classes = []\n",
    "\n",
    "for idx in range(NUM_IMG):\n",
    "    nhwc_img = np.transpose(features[idx], axes=(1, 2, 0))\n",
    "    imgs.append(nhwc_img)\n",
    "\n",
    "    model.eval()\n",
    "    _ , probas = model(features.to(device)[idx, None])\n",
    "    probas = probas.cpu().detach().numpy()\n",
    "\n",
    "    classes.append(\n",
    "        {\"class\": idx_to_class[np.argmax(probas[0])],\n",
    "         \"proba\": np.max(probas[0])})\n",
    "\n",
    "for i, ax in enumerate(axs.flat):\n",
    "    if i < len(imgs):\n",
    "        ax.imshow(imgs[i])\n",
    "        ax.set_title(f'Class: {classes[i][\"class\"]}, \\nProbability:  {classes[i][\"proba\"]:.4f}', fontsize=8)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Own photos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "path = \"CV_data/own_photos/\"\n",
    "classes = os.listdir(path)\n",
    "classes = [fldr for fldr in classes if not fldr.startswith('.')]\n",
    "\n",
    "print(classes)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(RESOLUTION),\n",
    "    transforms.CenterCrop(RESOLUTION),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "custom_test_dataset = datasets.ImageFolder(root=path, transform=transform)\n",
    "\n",
    "custom_test_loader = DataLoader(dataset=custom_test_dataset, \n",
    "                         batch_size=BATCH_SIZE, \n",
    "                         shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for batch_idx, (features, targets) in enumerate(custom_test_loader):\n",
    "\n",
    "    features = features\n",
    "    targets = targets\n",
    "    break\n",
    "\n",
    "NUM_IMG = 4\n",
    "fig, axs = plt.subplots(1, NUM_IMG)\n",
    "imgs = []\n",
    "classes = []\n",
    "\n",
    "for idx in range(NUM_IMG):\n",
    "    nhwc_img = np.transpose(features[idx], axes=(1, 2, 0))\n",
    "    imgs.append(nhwc_img)\n",
    "\n",
    "    model.eval()\n",
    "    _ , probas = model(features.to(device)[idx, None])\n",
    "    probas = probas.cpu().detach().numpy()\n",
    "\n",
    "    classes.append(\n",
    "        {\"class\": idx_to_class[np.argmax(probas[0])],\n",
    "         \"proba\": np.max(probas[0])})\n",
    "\n",
    "for i, ax in enumerate(axs.flat):\n",
    "    if i < len(imgs):\n",
    "        ax.imshow(imgs[i])\n",
    "        ax.set_title(f'Class: {classes[i][\"class\"]}, \\nProbability:  {classes[i][\"proba\"]:.4f}', fontsize=8)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from lib.nutrifacts import retrieve_nutrition_facts\n",
    "import json\n",
    "\n",
    "from IPython.core.display import HTML\n",
    "HTML(\"&micro;\")\n",
    "\n",
    "print(json.dumps(retrieve_nutrition_facts(classes[2][\"class\"]), indent=4))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "convnet-vgg16.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "maibi_cv2",
   "language": "python",
   "name": "maibi_cv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "371px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
